{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kian's yt Cookbook\n",
    "### Kian Hayes\n",
    "\n",
    "This notebook serves the purpose of documenting some of the techniques and Python scripts I used to create certain YT 3D renders. I'll first go through how YT makes a 3D render to set up some background and logic for certain commands that will be used in the scripts. I'll then move on to showing specific scripts, going in depth in what's happening inside of the code along with some of the results from those scripts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is 3D Rendering in YT?\n",
    "\n",
    "3D Rendering in YT is entirely object oriented. Every piece of a render is contained within a YT class object. These objects include the data itself, the volume that data is contained in, the Scene that hosts all objects, the Transfer Function, and the camera including its' lense. All of these objects must be initialized and certain commands called wihtin those objects in order for you to produce good renders. There's a nice graphic on the YT Project website demonstrating all these objects physically that I'll link in here. To put simply, all these objects interact with each other and effect the ray tracing that goes on under the hood of YT in order to produce a 3D render. \n",
    "\n",
    "<PHOTO>\n",
    "\n",
    "We'll now go into what all these objects are, what they do, and how they're called in a Python script."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class Objects within YT's 3D Rendering and Guided Example\n",
    "\n",
    "This section serves the purpose of explaining all the objects associate with 3D rendering and along the way mentioning some helpful tips that I've learned that make coding more efficient or certain commands that I've found create good renders. I'll go in depth on these concepts, spending time to really explain what's going on line by line so if you just want a quick example showing a full script I've made that will produce a 3D render then skip this part."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Data\n",
    "\n",
    "The data isn't necessarily an object, but it's important to call it and load it inside of your script so YT knows what data you're working with. This is done simply with the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yt\n",
    "import unyt\n",
    "from yt.visualization.volume_rendering.api import Scene, create_volume_source\n",
    "from yt.visualization.volume_rendering.transfer_function_helper import TransferFunctionHelper\n",
    "import numpy as np\n",
    "\n",
    "ds = yt.load('file.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, it's required that we have the many import statements at the top there since yt does not load the specific things associated with 3D Renders with just `import yt`. We'll use numpy for many things associated with converting numbers to log space later. \n",
    "\n",
    "The data is typically in the format HDF5. The data that we work with is mostly HDF5 so I'm not sure if YT is capable of loading other types of data. You likely won't have to worry about that with data from the Maestro and FLASH code as they output their plt files as HDF5. The argument passed into `load` can also be a path which is often how I do it since it's likely that my python script's working directory will not be where my data is stored. Within this, you can use the wildcard character to load all data in a directory following a defined pattern as in `yt.load('some/directory/with/data/plt_cnt_*')` which is useful when making time series movies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Data Volume Object\n",
    "\n",
    "There are several different volume objects that you can pass your loaded data into but the main one that I've used is the 'Sphere' object. It is initialized by doing the following"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = yt.load('file.h5')\n",
    "radius = (2e3, 'km')\n",
    "core = ds.sphere(ds.domain_center, radius)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a simple block of code but there are a lot of YT specific things going on the arguments that I would like to explain. First is defining the radius which is specifically associated with the radius of our Data Volume Object. I've made this a tuple where the zero element is the magnitude I want the radius to be and the first element the units I want that magnitude to be. This is a good variable to define at the beginning because there will be many situations where we only need the magnitude of the radius in future commands in which we can just write `radius[0]`. In other cases where we need both we just pass in the whole variable. \n",
    "\n",
    "Now for the `core` assignment which creates our Data Volume Object. The general call to assign our data to a volume is `ds.<volume_type>(center, radius_of_volume)` where `volume_type` can be any volume avaible within YT. It's important to note that the `center` argument must be a 3 dimensional cartesian coordinate within our data in the form of a list as in `[x, y, z]`, although we can use `ds.domain_center` which will return the center of our data without us having to do much work. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Field Volume Source\n",
    "\n",
    "Now that we have all our data inside of a volume, we need to create a seperate volume source for the specific field. This is done with the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "field = ('boxlib', 'X(na23)')\n",
    "my_source = create_volume_source(ds, field)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another useful tip I'd like to explain is done here. **Define the specific field you want to render at the beginning of your script**. There are A LOT of commands in YT that require you to pass in the field you're working with. It can be a pain to type the tuple with the two strings every time we need to do this so make your life easier and put it in a variable. \n",
    "\n",
    "With that out of the way, we then create our Field Volume Source with `yt.create_volume_source` where the arguments are first our dataset and then second our field we want to work with. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Transfer Function\n",
    "\n",
    "The Transfer Function is how YT relates your data values in the volume source to a color that is shown in the render. Working with this object is by far the most tedious thing when making 3D renders because changing one command with this function can dramatically effect how your 3D render looks. Setting up your Transfer Function correctly is a matter of seeing defining features within data or not so it takes a lot of tweaking values and patience. The transfer function is mainly editted through the TransferFunctionHelper class which we initialize with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfh = TransferFunctionHelper(ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the Transfer Function is initialized, we can call some commands to change it the way we want:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bounds = (1e6, 5e6)\n",
    "tfh.set_log(True)\n",
    "tfh.grey_opacity = False\n",
    "tfh.set_bounds(bounds)\n",
    "tfh.build_transfer_function()\n",
    "tfh.tf.map_to_colormap(np.log10(bounds[0]), np.log10(bounds[1]), colormap=\"twilight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, I like to define my bounds for easy edits. I find myself messing with the bounds a lot and as you can see there are many times where you'll need to pass in these numbers to different commands. \n",
    "\n",
    "`tfh.set_log(True)` simply makes our Transfer Function set in log space. I would always keep this as True because I've found changing to linear space can cause errors. Most fields are better visualized in log space anyway.\n",
    "\n",
    "I'm not entirely sure what `tfh.grey_opacity = False` does exaclty but I've always had it in my scripts. I believe it has to do with the transparency of your render.\n",
    "\n",
    "`tfh.set_bounds(bounds)` simply sets your bounds to the Transfer Function. **It is very important that you define this in your script because if not, YT will try to calculate bounds for you which increase the amount of time the script runs.** Just make it easy for YT and call this to begin with!\n",
    "\n",
    "Finally `tfh.build_transfer_function()` will update the current state of our transfer function. If you do anything to the transfer function after this it will not take effect unless you call it again. \n",
    "\n",
    "The next step is putting a color map on our transfer function. You can also put multiple gaussians on the transfer function but I like the results of putting the whole color map on the transfer function. `tfh.tf.map_to_colormap(np.log10(bounds[0]), np.log10(bounds[1]), colormap=\"twilight\")` sets the max and min bounds that our color map is mapped to on our transfer function. Obviously we want it to take up our entire transfer funciton so the bounds are the same as before usually. Next we define what color map. The various color maps we can use can be found online by googling \"Matplotlib Colormaps\". Using 'twilight' is a stylistic choice but you can use any of these Matplotlib colormaps found online. An example of using the Gaussians is the following (I don't use this method often because I don't like the results as much so this is the extent I'll go into with this method):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlayers = 10\n",
    "tfh.tf.add_layers(\n",
    "    nlayers,\n",
    "    w=0.01,\n",
    "    mi=np.log10(bounds[0]), # Sets the min x limit\n",
    "    ma=np.log10(bounds[1]), # Sets the max x limit\n",
    "    col_bounds=[-15, -8], # This changes the area of the color map that will be used\n",
    "    alpha=np.logspace(-1, 6, 20), # Changes the y-axis TransferFunction plot (how high the alpha value is)\n",
    "    colormap='twilight', # Changes the color map\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have everything set up with our transfer function, we can take it and apply it to our source(s):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_source.transfer_function = tfh.tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Scene and Camera\n",
    "\n",
    "The scene is the object that hosts all the other objects. It is initialized simply with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = Scene()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will mainly call `sc` in order to add our objects. We want to add our source to the scene so we'll say"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.add_source(my_source)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reminder that `my_source` is the **field volume source**, not to be confused with the data volume source. If we want to add multiple sources to the scene, we simply pass in a different source with the same command such as `sc.add_source(my_source2)`.\n",
    "\n",
    "Now we want to add our camera so we can actually see what we're looking at. The camera will take in the ray-tracing and produce our rendered picture. It can be added to the scene with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.add_camera(ds, lens_type=\"perspective\")\n",
    "sc.camera.focus = ds.domain_center\n",
    "sc.camera.resolution = 400\n",
    "sc.camera.north_vector = unyt.unyt_array([0., 1., 0.], 'km')\n",
    "sc.camera.position = ds.domain_center + unyt.unyt_array([0., 0., 0.80*radius[0]], 'km')\n",
    "sc.camera.set_width(radius)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`sc.add_camera` has two arguments, first the dataset, and second the lens_type which can be changed to a number of different lenses but you'll likely only use perspective. There are some whacky lenses you can use but perspective is most realistic. As you can see there are numerous things we can change about our camera such as position, resolution, and its framing. \n",
    "\n",
    "`sc.camera.focus = ds.domain_center` will make our camera point at the center of our data, using the same 3d coordinates as before. I haven't experimented with this parameter but I'm sure you can change it to point at different areas of interest within the data. \n",
    "\n",
    "`sc.camera.resolution` can take in a single integer or a tuple of integers to set the resolution of the final picture. When tweaking parameter I would keep this very low (around 300-500) because 3D rendering is an expensive process and increasing it to something like 1000 can dramatically increase your run time. \n",
    "\n",
    "`sc.camera.northvector = unyt.unyt_array([0., 1., 0.], 'km')` will orient your camera to a specific 3d vector. In this example, we've aligned the north vector of the camera to the y axis which means when we look at the source through our camera, the y-axis will be pointing up from our source. This is not to be confused with the normal vector to our source which would be the z axis in this case. We can think of the normal vector also being the vector from the center of our source to the camera.\n",
    "\n",
    "`sc.camera.position = ds.domain_center + unyt.unyt_array([0., 0., 0.80*radius[0]], 'km')` places our camera at a 3D coordinate. In this example we take the data domain center and then move it out from there along the z-axis. You can mess with this based on how big your source is. There are certain fields that will create bigger sources than others so if you find that the source is too small in your final render then increase how close it is. I'm not sure why we use the yt array as I've just always had that in my script. I'm not sure if you can use an np array. \n",
    "\n",
    "Lastly, `sc.camera.set_width(radius)` will set how wide our camera views. I'm not sure if this is the same as field of view but I just pass in the radius to this and change the camera position if I want to change how much the camera sees. I don't change this at all. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rendering\n",
    "\n",
    "We now have everything we need to call the render statement and save our render to disk which is done through the following"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.render()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We must call the scene itself and attach the method `render()` to it which will fully conduct the processing of the current state of the scene but in order to save a picture we use: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if yt.is_root():\n",
    "    sc.save(f'/gpfs/projects/CalderGroup/KianSpace/reu2023/plots/urca/3d_render_{field[1]}',\n",
    "            render=False, \n",
    "            sigma_clip=2\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "if yt.is_root()\n",
    "```\n",
    "Is important when we are running our script in parallel. `yt.is_root()` will return `True` when the current running process is on the root processor, that way we aren't saving our render for however many processes we have running. I'll get into running in parallel in a bit.\n",
    "\n",
    "```python\n",
    "sc.save(f'/gpfs/projects/CalderGroup/KianSpace/reu2023/plots/urca/3d_render_{field[1]}.png',\n",
    "            render=False, \n",
    "            sigma_clip=2\n",
    "    )\n",
    "```\n",
    "\n",
    "Will save our render to the specified path. It's good practice that we give our file name something unique. This will be very important when we get into making movies with our 3D renders. We should give out picture a name that is unique to the attribute we are changing and the field we are looking at. Try not to let yt give the file name automatically. Give it something that you yourself will be able to recognize and know what it is when looking for it later. I'll give some more tips on this when we get into making movies.\n",
    "\n",
    "If we do not include `render=False` to `save()` the scene will render again and we don't need that so try to include this when doing 3D renders. \n",
    "\n",
    "Lastly `sigma_clip=2` modifies the contrast of the scene in the final image. I like setting this to 2 because it makes the scene pretty bright and the colors vibrant\n",
    "\n",
    "Here's what we made:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"/gpfs/projects/CalderGroup/KianSpace/reu2023/plots/urca/3d_renders/frames/3d_render_X(na23).png\" height=500 width=500>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overview and Specific Tips\n",
    "\n",
    "This is the overarching process of every kind of 3D render with yt. Call all of these class objects, put them in the scene, call all the necessary commands associated with the objects and make your own stylistic choices with them. With that, we can now get into some more complicated stuff but before that, here are some useful tips to keep in mind as we continue:\n",
    "\n",
    "- Assign the field, Transfer Function bounds, and any other repeatedly used variable at the top of your scripts in a variable. \n",
    "- When figuring out bounds for your transfer function, it is easier to just pull up a seperate Jupyter Notebook and make a SlicePlot of the same field you're trying to render and figure out your Transfer Function through that. 3D rendering is a computationally expensive process while SlicePlots can be produced in a matter of seconds. By looking at the color bar ticks on the SlicePlot, you get a feel for what your bounds should be in order for your 3D render to look good. \n",
    "    - With that, you're able to plot the current state of your transfer function with `tfh.plot()` and get a nice graph to show you what color certain values will be. This is also nice when debugging and figuring out why certain 3D renders might look weird. Here's an example:\n",
    "- Figure out this initial 3D render and your Transfer Function before moving on to the more computational expensive movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "field = ('boxlib', 'radial_velocity')\n",
    "\n",
    "sc = Scene()\n",
    "\n",
    "radius = (1.8e3, 'km')\n",
    "\n",
    "core = ds.sphere(ds.domain_center, radius)\n",
    "my_source = create_volume_source(core, field)\n",
    "\n",
    "nlayers = 8\n",
    "\n",
    "bounds = (0.5e5, 10e5) \n",
    "\n",
    "tfh = TransferFunctionHelper(ds) \n",
    "tfh.set_field(field) \n",
    "tfh.set_log(True) \n",
    "tfh.grey_opacity = False\n",
    "tfh.set_bounds(bounds) \n",
    "tfh.build_transfer_function() \n",
    "\n",
    "tfh.tf.map_to_colormap(np.log10(bounds[0]), np.log10(bounds[1]), colormap=\"twilight\", scale=1e-1)\n",
    "\n",
    "my_source.transfer_function = tfh.tf\n",
    "\n",
    "tfh.plot()"
   ]
  },
  {
   "attachments": {
    "6fad1c7a-150b-45ff-b462-3da71fd1225c.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![6fad1c7a-150b-45ff-b462-3da71fd1225c.png](attachment:6fad1c7a-150b-45ff-b462-3da71fd1225c.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parallelism and 3D Rendering\n",
    "\n",
    "It is absolutely essential that we use parallelism to do 3D rendering. It is very simple in yt and will cut your runtime by significant factors, meaning you wait less time to mess with your transfer function 30 times. YT uses MPI to run in parallel and here's the general process:\n",
    "\n",
    "- Generally, you want to make a seperate Python script rather than using Jupyter Notebook because it's not possible to run in parallel in an interactive session. \n",
    "- To use MPI with python, mpi4py must be downloaded in the environment, with that, you must activate your envirnoment before you run the script.\n",
    "- At the top of your script, usually after the import statements, you want to put `yt.enable_parallelism()`. You can then make your script as usual. yt knows to run multiple processes if you tell it to with the enable parallelism. \n",
    "- After the script is made, you have to run your script on the terminal with the following command:\n",
    "\n",
    "```\n",
    "mpirun -np 8 python script.py\n",
    "```\n",
    "\n",
    "- Where `mpirun` calls MPI to run a script in parallel, `-np` option indicated the amount of processes to run, `python` says that the script is in python, and `<script.py>` is your python script file. 8 was an arbitrary number, but you can typically use all the cores on your node (given that you won't run into memory problems).\n",
    "\n",
    "## Running a time series dataset in parallel\n",
    "\n",
    "There are specific things that you need to include in your scripts if you're using multiple "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Camera Rotation Movies with 3D Renders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A regular 3D render is useful to just get going but what we really want to do is make movies with our source to really analyze the whole thing. A good way to do with is have the camera object rotate around our source. This section will go over how to do that assuming that you already know how to make a regular 3D render because this method is simply multiple 3D render stitched together. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to make the camera rotate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rotating the camera uses a simple method in yt itself embed inside of a for loop. The following will rotate your camera automatically with `for i in sc.camera.iter_rotate(2*np.pi, 36, rot_center=ds.domain_center)` where the first argument is the total angle you want the camera to rotate around, the second is the amount of steps it will take to get there, and the last is the point in the data that the camera will rotate around. Here, our camera will rotate 360 degrees around the center of source in 36 steps. 36 will be the total amount of pictures that will be output by this for loop so if you want a smoother video you may want to up this but it will take longer to complete. This is located at the end of my script after I've initialized everything about my scene. A full example will be shown as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in sc.camera.iter_rotate(2*np.pi, 36, rot_center=ds.domain_center):\n",
    "    sc.render()\n",
    "\n",
    "    if yt.is_root():\n",
    "        sc.save('your_path/3d_render.png', \n",
    "                render=False, \n",
    "                sigma_clip=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yt\n",
    "import os\n",
    "import unyt\n",
    "from yt.units import dimensions\n",
    "from yt.visualization.volume_rendering.transfer_function_helper import TransferFunctionHelper\n",
    "from yt.visualization.volume_rendering.api import Scene, create_volume_source, Camera, ColorTransferFunction\n",
    "import numpy as np\n",
    "\n",
    "yt.enable_parallelism()\n",
    "\n",
    "# Loading in data\n",
    "ds = yt.load('/gpfs/projects/CalderGroup/BrendanSpace/SIM_DATA/hires_urca_problem/plt0030084')\n",
    "\n",
    "# Setting our field we're looking at\n",
    "field = ('boxlib', 'Ye_sub')\n",
    "sc = Scene()\n",
    "\n",
    "# Setting the radius of the sphere that's rendered\n",
    "radius = (1.8e3, 'km')\n",
    "\n",
    "# Setting up the data to render as the Source part of the Scene (sc)\n",
    "core = ds.sphere(ds.domain_center, (500, 'km'))\n",
    "my_source = create_volume_source(core, field)\n",
    "my_source.set_log(False)\n",
    "\n",
    "# Transfer Function (Coloring)\n",
    "bounds = (2.8e-5, 3.5e-5) # These are the bounds for our transfer function\n",
    "tfh = TransferFunctionHelper(ds) # Transfer Functino object to help with syntax\n",
    "tfh.set_field(field) # Set what field we are looking at\n",
    "tfh.set_log(False) \n",
    "tfh.grey_opacity = True\n",
    "tfh.set_bounds(bounds) \n",
    "tfh.build_transfer_function()\n",
    "tfh.tf.map_to_colormap(bounds[0], bounds[1], colormap=\"twilight\") # Mapping our Transfer Funciton to color map\n",
    "my_source.transfer_function = tfh.tf # Add transfer function to our source\n",
    "sc.add_source(my_source) # Add source to scene\n",
    "\n",
    "# Camera\n",
    "sc.add_camera(ds, lens_type=\"perspective\") # Add Camera to scene\n",
    "\n",
    "# Camera properties\n",
    "sc.camera.focus = ds.domain_center # Pointing Camera to center\n",
    "sc.camera.resolution = 1000 # Resolution\n",
    "sc.camera.north_vector = unyt.unyt_array([0., 1., 0.], 'km') # Setting the \"up\" vectore for the camera\n",
    "\n",
    "# Camera Position and field of view\n",
    "sc.camera.position = ds.domain_center + unyt.unyt_array([0., 0., 0.80*radius[0]], 'km') # moving 3x away along z-direction\n",
    "sc.camera.set_width(radius)\n",
    "\n",
    "sc.annotate_axes(alpha=0.001)\n",
    "\n",
    "# Rotate around the object and render an image\n",
    "for i in sc.camera.iter_rotate(2*np.pi, 36, rot_center=ds.domain_center):\n",
    "    sc.render()\n",
    "\n",
    "    if yt.is_root():\n",
    "        sc.save(f'/gpfs/projects/CalderGroup/KianSpace/plots/urca/3d_renders/rotate/ye_sub/images/3d_render_{field[1]}_rot{i}.png', render=False, sigma_clip=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3D Render of Multiple Fields"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It may be useful to look at multiple fields in the same render. To do this, the logic we'll follow is adding more data sources to our scene that are looking at different fields we are interested in. This method can easily get out of hand by making seperate Transfer Functions for each source but for this example we will use the same Transfer Function for both sources. We'll follow the same process as before up until we get to creating our sources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yt\n",
    "from yt.visualization.volume_rendering.api import Scene, create_volume_source\n",
    "import unyt\n",
    "from yt.visualization.volume_rendering.transfer_function_helper import TransferFunctionHelper\n",
    "import numpy as np\n",
    "\n",
    "yt.enable_parallelism()\n",
    "\n",
    "ds = yt.load('/gpfs/projects/CalderGroup/BrendanSpace/SIM_DATA/hires_urca_problem/plt0030084')\n",
    "ds.force_periodicity()\n",
    "field1 = ('boxlib', 'rhoX(na23)')\n",
    "field2 = ('boxlib', 'rhoX(ne23)')\n",
    "\n",
    "sc = Scene()\n",
    "\n",
    "radius = (1.8e3, 'km')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that we've set the two fields we want to look at. We now want to create our sources with that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "core = ds.sphere(ds.domain_center, radius)\n",
    "volume1 = create_volume_source(core, field1)\n",
    "volume2 = create_volume_source(core, field2)\n",
    "volume1.set_log(False)\n",
    "volume2.set_log(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now apply our transfer function to these sources and then render."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transfer Function\n",
    "bounds = (7e5, 5e-4)\n",
    "tfh = TransferFunctionHelper(ds)\n",
    "tfh.set_log(False)\n",
    "tfh.grey_opacity = True\n",
    "tfh.set_bounds(bounds)\n",
    "tfh.build_transfer_function()\n",
    "\n",
    "tfh.tf.map_to_colormap(mi=bounds[0], ma=bounds[1], scale=2, colormap=\"twilight\")\n",
    "\n",
    "volume1.transfer_function = tfh.tf\n",
    "volume2.transfer_function = tfh.tf\n",
    "\n",
    "# Adding sources to Scene\n",
    "sc.add_source(volume1)\n",
    "sc.add_source(volume2)\n",
    "\n",
    "# Camera\n",
    "sc.add_camera(ds, lens_type=\"perspective\")\n",
    "sc.camera.focus = ds.domain_center\n",
    "sc.camera.resolution = 500\n",
    "sc.camera.north_vector = unyt.unyt_array([0., 1., 0.], 'km')\n",
    "sc.camera.position = ds.domain_center + unyt.unyt_array([0., 0., 0.80*radius[0]], 'km')\n",
    "sc.camera.set_width(radius)\n",
    "\n",
    "# Render\n",
    "sc.render()\n",
    "if yt.is_root():\n",
    "    sc.save(f\"/gpfs/projects/CalderGroup/KianSpace/reu2023/plots/urca/3d_renders/frames/{field1[1]}_{field2[1]}_3d_render\", render=False, sigma_clip=2)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
